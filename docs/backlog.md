# Project Backlog

| Epic | Task Description | Acceptance Criteria | Status | Prototype | Notes |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **CI/CD & Deployment** | Setup GitHub Actions workflow for CI/CD | - Compile project with GitHub Packages authentication<br>- Run all tests<br>- Create semantic version release<br>- Build Docker image with proper tagging<br>- Publish to GitHub Container Registry<br>- Only deploy on successful release | `Complete` |  | Updated .github/workflows/ci.yml with full CI/CD pipeline. Build-and-test job runs compile/test with GitHub Packages auth. Semantic release creates versions. Docker job builds and pushes to ghcr.io with semantic version tags. Dockerfile updated to accept build args for GitHub credentials. |
| **Testing & Quality** | Create comprehensive test suite for critical components | - Test domain models (ValueObjects, ScheduleRequest, ScheduleType, ScheduledMessage)<br>- Test API layer (ScheduleRequestParser)<br>- Test configuration validation<br>- All tests passing<br>- Good code coverage on business logic | `Complete` |  | Created 6 test specs with 54 tests covering domain, API, and config validation. All tests passing. Includes edge cases, validation, and error handling. |
| **Library Migration** | Migrate to Byrde commons logging library | - Replace scala-logging/logback with Byrde commons logging<br>- Update all logger instances across codebase<br>- Update build.sbt dependencies<br>- Verify structured logging works<br>- Test log output format | `Complete` |  | Successfully migrated to org.byrde.logging.ScalaLogger across Main, HealthCheckServer, DatabaseManager, MessageScheduler, and PubSubClient. Dependencies loaded from GitHub Packages. Compiles successfully. |
| **Library Migration** | Migrate to Byrde commons PubSub library | - Replace google-cloud-pubsub with Byrde commons pubsub<br>- Refactor PubSubClient to use commons API<br>- Refactor PubSubSubscriber to use commons API<br>- Update configuration for commons library<br>- Update build.sbt dependencies<br>- Verify subscriber and publisher work<br>- Update health checks if needed | `Complete` |  | Migrated to org.byrde.pubsub using GooglePubSubPublisher and GooglePubSubSubscriber. Config now uses CommonsPubSubConfig with credentials loaded via Google Auth. All 53 tests passing. Validated: compiles, tests pass. |
| **Pub/Sub Message Ingestion** | Implement Pub/Sub subscriber to receive schedule requests | - Subscriber connects to configured subscription<br>- Messages are acknowledged after processing<br>- Connection errors are logged and retried<br>- Manual CLI command to test subscription | `Complete` |  | Implemented in PubSubSubscriber.scala. Validated: connects via config, Ack/Nack handled, errors logged, CLI start command available. |
| **Pub/Sub Message Ingestion** | Parse and validate incoming schedule request messages | - Parse JSON message body into ScheduleRequest domain model<br>- Validate execution time is in future<br>- Validate target topic format<br>- Validate payload is non-empty<br>- Return validation errors for invalid messages | `Complete` |  | Implemented in ScheduleRequestParser.scala with Circe JSON parsing. 10 unit tests cover all validation criteria. |
| **Database-Backed Scheduling** | Configure db-scheduler with Cloud SQL database support | - Support PostgreSQL, MySQL, and SQL Server via JDBC<br>- Initialize db-scheduler schema on startup<br>- Configure connection pooling<br>- Handle database connection failures gracefully | `Complete` |  | Implemented with HikariCP in DatabaseManager.scala. Supports PostgreSQL/MySQL/SQL Server auto-detection, connection pooling, graceful error handling. |
| **Database-Backed Scheduling** | Create scheduled tasks from validated schedule requests | - Convert ScheduleRequest to db-scheduler task<br>- Persist task to database with execution time<br>- Store target topic and payload in task data<br>- Return task ID for tracking | `Complete` |  | Implemented in MessageScheduler.scala with JSON serialization. ScheduledMessageData stores topic/payload, TaskId returned. |
| **Database-Backed Scheduling** | Implement task execution handler | - db-scheduler triggers handler at execution time<br>- Deserialize target topic and payload from task data<br>- Publish payload to target topic via Pub/Sub<br>- Mark task as completed on success<br>- Handle publish failures with retries | `Complete` |  | Implemented in MessageScheduler.executeTask with error handling. Deserializes data, publishes to PubSub, throws on failure for retry. |
| **Dynamic Topic Routing** | Support dynamic topic routing from message payload | - Extract target topic from schedule request<br>- Validate topic exists or can be created<br>- Publish to dynamically specified topic<br>- Handle topic permission errors | `Complete` |  | Implemented with TargetTopic value object supporting both simple and full topic paths. Validated in parser and used at execution. |
| **Docker Deployment** | Create Dockerfile for portable deployment | - Multi-stage build for Scala application<br>- Minimal base image (JRE 11+)<br>- Environment variable configuration<br>- Health check endpoint<br>- Image builds and runs successfully | `Complete` |  | Configured via sbt-native-packager in build.sbt. Uses temurin:11-jre-jammy, health check on port 8080, published via CI. |
| **Docker Deployment** | Implement environment-based configuration | - Database connection string from env var<br>- Pub/Sub project ID from env var<br>- Pub/Sub credentials from file path or env var<br>- Subscription name from env var<br>- Validate all required config on startup | `Complete` |  | Implemented in Config.scala with Typesafe Config and env var overrides. Supports DATABASE_URL, PUBSUB_PROJECT_ID, PUBSUB_SUBSCRIPTION, PUBSUB_CREDENTIALS_PATH. |
| **Deployment Documentation** | Create deployment guide for standing up the service | - Document Cloud SQL database provisioning<br>- Document Pub/Sub topic and subscription setup<br>- Document service account permissions required<br>- Document environment variable configuration<br>- Provide Docker run command examples<br>- Include troubleshooting section | `Complete` |  | Created docs/DEPLOYMENT.md with comprehensive deployment guide covering Cloud SQL setup, Pub/Sub configuration, IAM roles, Docker/Cloud Run deployment, health checks, and troubleshooting. Validated all acceptance criteria. |
| **Deployment Documentation** | Document message format and API contract | - Document JSON schema for schedule request messages<br>- Provide message examples<br>- Document error handling and dead-letter queue setup<br>- Document monitoring and logging approach | `Complete` |  | Created docs/API.md with JSON schema, schedule type examples, validation rules, error handling, DLQ setup, and monitoring guidance. Validated against ScheduleRequestParser and ScheduleType implementations. |
| **Operational Health** | Implement comprehensive health check for downstream services | - Health endpoint actively checks database connectivity<br>- Health endpoint actively checks PubSub connectivity<br>- Return detailed status per service<br>- Return 503 if any service is unhealthy<br>- Include response time metrics | `Complete` |  | Enhanced HealthCheckServer with DatabaseManager and PubSubClient health checks. Returns JSON with per-service status, response times, and 503 on failure. |
| **HTTP Management API** | Implement Basic Auth for HTTP API | - Support HTTP Basic Authentication<br>- Username and password injected via environment variables (API_USERNAME, API_PASSWORD)<br>- Return 401 for missing/invalid credentials<br>- Log authentication attempts (success and failure)<br>- Framework: Tapir + Vert.x with Swagger/OpenAPI | `Ready to Test` |  | Implemented HttpApiServer with Tapir + Vert.x. Basic auth optional via API_USERNAME/API_PASSWORD env vars. POST /schedule endpoint with Swagger UI at /docs. |
| **HTTP Management API** | Create POST /schedule endpoint for direct message scheduling | - Accept JSON schedule request in body<br>- Authenticate and authorize request<br>- Validate request using ScheduleRequestParser<br>- Schedule message using MessageScheduler<br>- Return task ID and status (201 Created)<br>- Return validation errors (400)<br>- Handle internal errors (500) | `TODO` |  | Tapir endpoint with Swagger docs |
| **HTTP Management API** | Create GET /schedule endpoint to list scheduled messages | - Return paginated list of scheduled messages<br>- Support filtering by status (pending, executed, cancelled, failed)<br>- Support filtering by date range<br>- Include task ID, status, execution time, target topic<br>- Authenticate and authorize request | `TODO` |  | Tapir endpoint with Swagger docs |
| **HTTP Management API** | Create GET /schedule/:id endpoint to retrieve a scheduled message | - Return full details of a specific scheduled message<br>- Include task ID, status, execution time, target topic, payload<br>- Return 404 if task not found<br>- Authenticate and authorize request | `TODO` |  | Tapir endpoint with Swagger docs |
| **HTTP Management API** | Create DELETE /schedule/:id endpoint to cancel a scheduled message | - Cancel a pending scheduled message by task ID<br>- Only allow cancellation of pending tasks<br>- Return 200 with cancelled task details on success<br>- Return 404 if task not found<br>- Return 409 Conflict if task already executed or cancelled<br>- Authenticate and authorize request | `TODO` |  | Tapir endpoint with Swagger docs |
| **HTTP Management API** | Implement rate limiting for HTTP API | - Per-client rate limiting based on auth identity<br>- Configurable limits (requests per minute/hour)<br>- Return 429 Too Many Requests when limit exceeded<br>- Include rate limit headers in responses | `TODO` |  | Prevent API abuse. Consider Tapir interceptor or Vert.x handler. |
| **HTTP Management API** | Add audit logging for HTTP API requests | - Log all authenticated requests<br>- Include client identity, timestamp, request details<br>- Log success/failure and response codes<br>- Include correlation IDs for tracing<br>- Support structured logging format | `TODO` |  | Security audit trail via Tapir interceptor |
| **Task Cancellation** | Implement task cancellation in domain layer | - Add TaskStatus value object with states: Pending, Executed, Cancelled, Failed<br>- Add cancel method to ScheduledMessage aggregate<br>- Enforce cancellation invariant (only pending tasks can be cancelled)<br>- Make cancellation idempotent | `TODO` |  | Domain support for cancellation |
| **Task Cancellation** | Implement task cancellation in MessageScheduler | - Add cancelTask method to MessageScheduler<br>- Use db-scheduler API to cancel/remove scheduled task<br>- Update task status in database<br>- Return success/failure result | `TODO` |  | Infrastructure support for cancellation |
| **Task Cancellation** | Implement task query methods in MessageScheduler | - Add getTask method to retrieve task by ID<br>- Add listTasks method with filtering and pagination<br>- Query db-scheduler's scheduled_tasks table<br>- Map database records to ScheduledMessage domain objects | `TODO` |  | Query infrastructure for API |
| **Keyless Authentication** | Configure Application Default Credentials (ADC) support | - Use Google Auth library's default credential chain<br>- Support GOOGLE_APPLICATION_CREDENTIALS env var for local dev<br>- Support metadata server credentials in Cloud Run/GCE<br>- Remove requirement for explicit credentials file path<br>- Update PubSubClient to use ADC | `TODO` |  | Built-in metadata server auth for Cloud Run |
| **Keyless Authentication** | Configure Workload Identity Federation (WIF) support | - Support external identity providers (AWS, Azure, OIDC)<br>- Configure credential configuration file path<br>- Use Google Auth library's WIF support<br>- Document WIF setup for common providers | `TODO` |  | WIF for multi-cloud/external workloads |
| **Keyless Authentication** | Update Docker and deployment configuration for keyless auth | - Update Dockerfile to not require credentials file<br>- Update environment variable documentation<br>- Add Cloud Run deployment example<br>- Document service account requirements<br>- Update health checks for credential validation | `TODO` |  | Deployment updates for keyless auth |

Notes:
- The `Status` column must follow: `TODO` → `In Progress` → `Ready to Test` → `Complete`.
- The `Prototype` column is maintained by the prototyping workflow. Leave it empty for new tasks. When a prototype is created, this column should include where to find it (e.g., `prototypes/[task-or-feature].[ext]`) plus a brief note on scope/findings.

